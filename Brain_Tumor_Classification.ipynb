{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam101/Biomedical-Image-Processing/blob/main/Copy_of_Biomedical_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs3aiQyeygvn"
      },
      "source": [
        "#3.  Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/Brain tumor (2).zip\""
      ],
      "metadata": {
        "id": "64WFOSg2O40f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZm8abfRz74m"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j71XEnVBy6xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa260964-2ba6-410a-d0d7-cbb6394a76ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'TEST' created\n",
            "Directory 'Validation' created\n"
          ]
        }
      ],
      "source": [
        "#create the testset\n",
        "  \n",
        "# Directory\n",
        "directory = \"TEST\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/Brain tumor\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "print(\"Directory '% s' created\" % directory)\n",
        "\n",
        "#create the Validation  \n",
        "# Directory\n",
        "directory = \"Validation\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/Brain tumor\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "print(\"Directory '% s' created\" % directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3bJcpFJzJ84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419fc795-e080-4f31-c85b-0588b1e3314d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes: 155\n",
            "No: 98\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'Brain_tumor_detection'\n",
        "\n",
        "TRAIN_DIR=[\"/content/Brain tumor/brain_tumor_dataset/yes\", \"/content/Brain tumor/brain_tumor_dataset/no\"]\n",
        "VALID_DIR=\"/content/Brain tumor/Validation\"\n",
        "\n",
        "img_size=224\n",
        "lr=3e-5\n",
        "\n",
        "#Count the number of images in each class\n",
        "for dir_path in TRAIN_DIR:\n",
        "  count=len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
        "  if dir_path == TRAIN_DIR[0]:\n",
        "    print(\"Yes:\", count)\n",
        "  else:\n",
        "    print(\"No:\", count)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDh7KVug0FLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a3f06b-ec8c-452c-a546-6038c289b01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test length:  22\n",
            "Validation length:  49\n"
          ]
        }
      ],
      "source": [
        "#Splitting Data\n",
        "#Create Test Set\n",
        "# 10% images from each class are moved to Test folder \n",
        "import shutil\n",
        "\n",
        "# absolute path\n",
        "src_path1 = r\"/content/Brain tumor/brain_tumor_dataset/yes\"\n",
        "src_path2 = r\"/content/Brain tumor/brain_tumor_dataset/no\"\n",
        "dst_path = r'/content/Brain tumor/TEST'\n",
        "\n",
        "\n",
        "YES= os.listdir(src_path1)\n",
        "NO = os.listdir(src_path2)\n",
        "\n",
        "#Moving Yes\n",
        "for i in range (0, 14):      \n",
        "      file_name= YES[i]\n",
        "      # construct full file path\n",
        "      source = src_path1 + '/'+file_name\n",
        "      destination = dst_path  +'/'+file_name\n",
        "      # move only files\n",
        "      if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "#Moving NO\n",
        "for i in range (0, 8):      \n",
        "      file_name= NO[i]\n",
        "      # construct full file path\n",
        "      source = src_path2 + '/'+file_name\n",
        "      destination = dst_path+ '/'+file_name\n",
        "\n",
        "      # move only files\n",
        "      if os.path.isfile(source):\n",
        "          shutil.move(source, destination)\n",
        "        \n",
        "TEST=os.listdir(dst_path)\n",
        "print(\"Test length: \",len(TEST))\n",
        "\n",
        "#Create Validation Set\n",
        "# Moving 20% of images in each class to Validation Folder \n",
        "# absolute path\n",
        "src_path1 = r\"/content/Brain tumor/brain_tumor_dataset/yes\"\n",
        "src_path2 = r\"/content/Brain tumor/brain_tumor_dataset/no\"\n",
        "dst_path = r\"/content/Brain tumor/Validation\"\n",
        "\n",
        "\n",
        "YES = os.listdir(src_path1)\n",
        "NO = os.listdir(src_path2)\n",
        "\n",
        "for i in range (0, 30):      \n",
        "      file_name= YES[i]\n",
        "      # construct full file path\n",
        "      source = src_path1 + '/'+file_name\n",
        "      destination = dst_path  +'/'+file_name\n",
        "      # move only files\n",
        "      if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "for i in range (0, 19):      \n",
        "      file_name= NO[i]\n",
        "      # construct full file path\n",
        "      source = src_path2 + '/'+file_name\n",
        "      destination = dst_path+ '/'+file_name\n",
        "\n",
        "      # move only files\n",
        "      if os.path.isfile(source):\n",
        "          shutil.move(source, destination)\n",
        "        \n",
        "\n",
        "validation=os.listdir(dst_path)\n",
        "print(\"Validation length: \",len(validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxB_vBck1kaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9e3062-5b8e-454f-f94a-ad4f007b54f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "633\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "#Augmentation\n",
        "path = r\"/content/Brain tumor/brain_tumor_dataset/yes\"\n",
        "\n",
        "num_images = 300\n",
        "\n",
        "# Define the augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5)\n",
        "])\n",
        "\n",
        "images = []\n",
        "for i in os.listdir(path):\n",
        "    img = cv2.imread(os.path.join(path, i))#\n",
        "    images.append(img)\n",
        "\n",
        "while len(images) < num_images:\n",
        "    aug_data = transform(image=images[np.random.randint(len(images))]) \n",
        "    print(aug_data)\n",
        "    aug_img = aug_data['image']\n",
        "    images.append(aug_img)\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "for i in range(len(images)):\n",
        "    aug_img = images[i ]\n",
        "    cv2.imwrite(os.path.join(path, f\"aug_{i}YES.JPG\"), aug_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vksh0-78190R"
      },
      "outputs": [],
      "source": [
        "#Preprocessing\n",
        "#Augmentation\n",
        "path = r\"/content/Brain tumor/brain_tumor_dataset/no\"\n",
        "\n",
        "num_images = 310\n",
        "\n",
        "# Define the augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5)\n",
        "])\n",
        "\n",
        "images = []\n",
        "for i in os.listdir(path):\n",
        "    img = cv2.imread(os.path.join(path, i))\n",
        "    images.append(img)\n",
        "\n",
        "while len(images) < num_images:\n",
        "    aug_data = transform(image=images[np.random.randint(len(images))])\n",
        "    aug_img = aug_data['image']\n",
        "    images.append(aug_img)\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "for i in range(len(images)):\n",
        "    aug_img = images[i ]\n",
        "    cv2.imwrite(os.path.join(path, f\"aug_{i}NO.JPG\"), aug_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnfrSzUn2NI1"
      },
      "outputs": [],
      "source": [
        "def create_label(directory):\n",
        "    if directory == TRAIN_DIR[0]:\n",
        "        return np.array([1,0]) # YES\n",
        "    elif directory == TRAIN_DIR[1]:\n",
        "        return np.array([0,1]) # NO\n",
        "    elif directory[32]==\"Y\":\n",
        "        return np.array([1,0])\n",
        "    elif directory[32]==\"N\":\n",
        "        return np.array([0,1])\n",
        "\n",
        "def create_train_data():\n",
        "  training_data = []\n",
        "  for i in range(len(TRAIN_DIR)):\n",
        "        for img in tqdm(os.listdir(TRAIN_DIR[i])[:]):\n",
        "            path = os.path.join(TRAIN_DIR[i], img)\n",
        "            img_data = cv2.imread(path, 0)\n",
        "            img_data = cv2.resize(img_data, (img_size, img_size))\n",
        "            label=create_label(TRAIN_DIR[i])\n",
        "            training_data.append((img_data, label))       \n",
        "  shuffle(training_data)\n",
        "  np.save('train_data.npy', training_data)\n",
        "  return np.array(training_data)\n",
        "\n",
        "\n",
        "def create_validation_data():\n",
        "    validation_data = []\n",
        "    for img in tqdm(os.listdir(VALID_DIR)):\n",
        "        path = os.path.join(VALID_DIR, img)\n",
        "        img_data = cv2.imread(path, 0)\n",
        "        img_data = cv2.resize(img_data, (img_size, img_size))\n",
        "        label = create_label(path)  # Pass the directory to create_label()\n",
        "        validation_data.append((img_data, label))\n",
        "    shuffle(validation_data)\n",
        "    np.save('validation_data.npy', validation_data)\n",
        "    return np.array(validation_data)\n",
        "\n",
        "\n",
        "if (os.path.exists('train_data.npy')):  # If you have already created the dataset:\n",
        "    train_data = np.load('train_data.npy', allow_pickle=True)\n",
        "\n",
        "else:\n",
        "    train_data = create_train_data()\n",
        "\n",
        "if (os.path.exists('validation_data.npy')):  # If you have already created the dataset:\n",
        "    validation_data = np.load('validation_data.npy', allow_pickle=True)\n",
        "\n",
        "else:\n",
        "    validation_data = create_validation_data()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLZ90YW12W0C"
      },
      "outputs": [],
      "source": [
        "train=train_data\n",
        "validation=validation_data\n",
        "\n",
        "#split img from its label\n",
        "x_train= np.array([i[0] for i in train]).reshape(-1, img_size, img_size,1)\n",
        "y_train = [i[1] for i in train]\n",
        "\n",
        "x_validate= np.array([i[0] for i in validation]).reshape(-1, img_size, img_size,1)\n",
        "y_validate = [i[1] for i in validation]\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_validate = x_validate.astype(\"float32\") / 255.0\n",
        "\n",
        "X_train = np.stack(x_train).reshape(-1, img_size,img_size, 1)\n",
        "X_validate = np.stack(x_validate).reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "y_train = np.stack(y_train).reshape(X_train.shape[0], 2)\n",
        "y_validate = np.stack(y_validate).reshape(X_validate.shape[0],2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp1MpFf-oO95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbaa1734-823d-4e3d-a23e-e6d32c51cb5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 224, 224, 64)      640       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,267,586\n",
            "Trainable params: 134,267,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 4s 523ms/step - loss: 0.6921 - accuracy: 0.5714 - val_loss: 0.6873 - val_accuracy: 0.6122\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 3s 479ms/step - loss: 0.6702 - accuracy: 0.6099 - val_loss: 0.6580 - val_accuracy: 0.6122\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 3s 481ms/step - loss: 0.6490 - accuracy: 0.6099 - val_loss: 0.6419 - val_accuracy: 0.6122\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 3s 482ms/step - loss: 0.6349 - accuracy: 0.6154 - val_loss: 0.6212 - val_accuracy: 0.6122\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 3s 471ms/step - loss: 0.5955 - accuracy: 0.6484 - val_loss: 0.5917 - val_accuracy: 0.7143\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 3s 487ms/step - loss: 0.5482 - accuracy: 0.7198 - val_loss: 0.5830 - val_accuracy: 0.7551\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 3s 473ms/step - loss: 0.5481 - accuracy: 0.7473 - val_loss: 0.5611 - val_accuracy: 0.6735\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 3s 479ms/step - loss: 0.5112 - accuracy: 0.7582 - val_loss: 0.5743 - val_accuracy: 0.7347\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 3s 483ms/step - loss: 0.5020 - accuracy: 0.7912 - val_loss: 0.5479 - val_accuracy: 0.7347\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 3s 482ms/step - loss: 0.5047 - accuracy: 0.7637 - val_loss: 0.6056 - val_accuracy: 0.7755\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 3s 485ms/step - loss: 0.4915 - accuracy: 0.7802 - val_loss: 0.5302 - val_accuracy: 0.7551\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 3s 498ms/step - loss: 0.4749 - accuracy: 0.7802 - val_loss: 0.5380 - val_accuracy: 0.7347\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 3s 509ms/step - loss: 0.4622 - accuracy: 0.7692 - val_loss: 0.5259 - val_accuracy: 0.7755\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 3s 493ms/step - loss: 0.4603 - accuracy: 0.7747 - val_loss: 0.5109 - val_accuracy: 0.7551\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 3s 501ms/step - loss: 0.4510 - accuracy: 0.7857 - val_loss: 0.5086 - val_accuracy: 0.7551\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 0.4220 - accuracy: 0.7857 - val_loss: 0.5659 - val_accuracy: 0.7755\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 0.4156 - accuracy: 0.8132 - val_loss: 0.5020 - val_accuracy: 0.7551\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 3s 515ms/step - loss: 0.4067 - accuracy: 0.7967 - val_loss: 0.5127 - val_accuracy: 0.7755\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 0.3777 - accuracy: 0.8242 - val_loss: 0.5914 - val_accuracy: 0.7551\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 3s 515ms/step - loss: 0.3382 - accuracy: 0.8462 - val_loss: 0.5477 - val_accuracy: 0.7347\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 0.3169 - accuracy: 0.8516 - val_loss: 0.5742 - val_accuracy: 0.7551\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "from keras import callbacks\n",
        "import keras\n",
        "from keras.models import Sequential                        # This gets our neuralnetwork as Sequential network as we know it can be sequential layers or graph.\n",
        "from tensorflow.keras.layers import Conv2D                 # We are working with images. All the images are basically 2D.\n",
        "from tensorflow.keras.layers import MaxPooling2D           # We choose max pooling.\n",
        "from tensorflow.keras.layers import Flatten                # The process of converting all the resultant 2D arrays into a single long continous linear vector.\n",
        "from tensorflow.keras.layers import Dense                  # The last step! The full connection of the neural network is performed with this Dense.\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "#Defining input image shape\n",
        "_input = Input((img_size, img_size,1))\n",
        "\n",
        "#Building VGG-16 Model\n",
        "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
        "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
        "pool1  = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
        "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
        "pool2  = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
        "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
        "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
        "pool3  = MaxPooling2D((2, 2))(conv7)\n",
        "\n",
        "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
        "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
        "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
        "pool4  = MaxPooling2D((2, 2))(conv10)\n",
        "\n",
        "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
        "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
        "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
        "pool5  = MaxPooling2D((2, 2))(conv13)\n",
        "\n",
        "flat   = Flatten()(pool5)\n",
        "#fully connected layers\n",
        "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
        "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
        "output = Dense(2, activation=\"softmax\")(dense2)\n",
        "\n",
        "vgg16_model  = Model(inputs=_input, outputs=output)\n",
        "vgg16_model.summary()\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=3e-5)\n",
        "vgg16_model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
        "\n",
        "from keras.models import load_model\n",
        "if (os.path.exists('model.tfl')):\n",
        "    vgg16_model=load_model('./model.tfl')\n",
        "else:\n",
        "    # Fit the model using the perturbed data\n",
        "    vgg16_model.fit( x_train,  y_train,\n",
        "                    validation_data=(x_validate, y_validate),\n",
        "                    epochs=30, callbacks=[early_stop],\n",
        "                    batch_size=32)\n",
        "    vgg16_model.save('Vgg16_model.tfl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP05OS3aqFOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "dafc041c-0ed6-43bd-8676-c77c51c67ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 151ms/step\n",
            "34\n",
            "15\n",
            "49\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7551020408163265\n",
            "F1 score: 0.7483493397358945\n",
            "Recall: 0.7551020408163265\n",
            "Precision: 0.7525410164065625\n"
          ]
        }
      ],
      "source": [
        "#Model Evaluation\n",
        "y_pred = vgg16_model.predict(x_validate)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "NO=0\n",
        "YES=0\n",
        "for i in y_pred_classes:\n",
        "  if i==0:\n",
        "    NO+=1\n",
        "  else:\n",
        "    YES+=1\n",
        "print(NO)\n",
        "print(YES)  \n",
        "print(len(y_pred_classes))\n",
        "\n",
        "#Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_validate, axis=1), y_pred_classes)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "\n",
        "# Define the class labels\n",
        "classes = ['Yes', 'No']\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in np.ndindex(cm.shape):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "acc = accuracy_score(np.argmax(y_validate, axis=1), y_pred_classes)\n",
        "f1 = f1_score(np.argmax(y_validate, axis=1), y_pred_classes, average='weighted')\n",
        "recall = recall_score(np.argmax(y_validate, axis=1), y_pred_classes, average='weighted')\n",
        "precision = precision_score(np.argmax(y_validate, axis=1), y_pred_classes, average='weighted')\n",
        "\n",
        "print('Validation Accuracy:', acc)\n",
        "print('F1 score:', f1)\n",
        "print('Recall:', recall)\n",
        "print('Precision:', precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08kGvjLWqmsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5ce379-fd5d-4066-9a47-64ca634efeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "/content/Brain tumor/TEST/Y53.jpg\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "/content/Brain tumor/TEST/NO (72).jpg\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "/content/Brain tumor/TEST/Y107.jpg\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "/content/Brain tumor/TEST/Y58.JPG\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "/content/Brain tumor/TEST/NO (91).jpg\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "/content/Brain tumor/TEST/NO (85).jpg\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "/content/Brain tumor/TEST/NO (56).jpg\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "/content/Brain tumor/TEST/Y60.jpg\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "/content/Brain tumor/TEST/Y251.JPG\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "/content/Brain tumor/TEST/NO (74).jpg\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "/content/Brain tumor/TEST/Y34.jpg\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "/content/Brain tumor/TEST/NO (7).jpg\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "/content/Brain tumor/TEST/Y30.jpg\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "/content/Brain tumor/TEST/NO (54).jpg\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "/content/Brain tumor/TEST/NO (86).jpg\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "/content/Brain tumor/TEST/Y185.jpg\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "/content/Brain tumor/TEST/Y112.JPG\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "/content/Brain tumor/TEST/Y255.JPG\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "/content/Brain tumor/TEST/Y92.png\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "/content/Brain tumor/TEST/Y114.JPG\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "/content/Brain tumor/TEST/Y7.jpg\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "/content/Brain tumor/TEST/Y14.jpg\n",
            "12\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "#Test\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "paths = []\n",
        "\n",
        "\n",
        "Test_Dir='/content/Brain tumor/TEST'\n",
        "for img in os.listdir(Test_Dir):\n",
        "    path = os.path.join(Test_Dir, img)\n",
        "    paths.append(path)\n",
        "\n",
        "import cv2\n",
        "names = []\n",
        "rows = []\n",
        "NO=0\n",
        "YES=0\n",
        "for img in paths:\n",
        "        label=''\n",
        "        names.append(img[:])\n",
        "        path = os.path.join(Test_Dir, img)\n",
        "        img_data = cv2.imread(path, 0)\n",
        "        img_data = cv2.resize(img_data, (224, 224))\n",
        "        img_data = img_data.reshape(224,224,1)\n",
        "        prediction =vgg16_model.predict(img_data.reshape(-1,224,224,1))[0]\n",
        "        #print(prediction[:].tolist())\n",
        "        max_value = max(prediction[:].tolist())\n",
        "        index = prediction[:].tolist().index(max_value)\n",
        "        if index == 0:\n",
        "          label=\"Yes\"\n",
        "          rows.append(\"Yes\")\n",
        "            \n",
        "        else:\n",
        "            label=\"No\"\n",
        "            rows.append(\"No\")\n",
        "        print(img)   \n",
        "        if img[26]==\"Y\" and label == \"Yes\":\n",
        "          YES+=1\n",
        "        elif img[26]==\"N\" and label ==\"No\":\n",
        "          NO+=1   \n",
        "\n",
        "dict = {\"image_name\": names, \"label\": rows}\n",
        "df = pd.DataFrame(dict)\n",
        "print(YES)\n",
        "print(NO)\n",
        "# saving the dataframe\n",
        "df.to_csv('final.csv',index=False)\n",
        "#14 8"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OHyOBHHeRD2M",
        "Gs3aiQyeygvn"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
